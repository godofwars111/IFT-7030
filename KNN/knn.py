# -*- coding: utf-8 -*-
"""KNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sXCpwzVWsOGBcETQDUNQvoHaZV5IX677
"""

from google.colab import files
import zipfile
import os

# Upload the dataset
uploaded = files.upload()

# Extract the zip file
zip_file = "sound-classification-of-animal-voice.zip"
with zipfile.ZipFile(zip_file, 'r') as zip_ref:
    zip_ref.extractall("animal_sounds")

# Verify files were extracted
print("Extracted files:", os.listdir("animal_sounds"))

!pip install librosa matplotlib scikit-learn

import os
import librosa
import numpy as np
from scipy.fftpack import dct
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns

###Original KNN implementation
def extract_features(file_path):
    y, sr = librosa.load(file_path, sr=None)

    # MFCC
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

    # Extraction des features
    features = np.concatenate((mfcc.mean(axis=1), mfcc.std(axis=1)))

    return features

# Initialize arrays
file_paths = []
labels = []
features = []

# Dataset path
folder_path = "animal_sounds"

# Iterate over files and extract features
for root, dirs, files in os.walk(folder_path):
    for file in files:
        if file.endswith(".wav") or file.endswith(".mp3"):
            file_path = os.path.join(root, file)
            label = os.path.basename(root)
            file_paths.append(file_path)
            labels.append(label)
            features.append(extract_features(file_path))

# Convert to numpy arrays
X = np.array(features)
y = np.array(labels)

# Division des données en train et test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3, weights='distance')

# Entraînement du KNN
knn.fit(X_train, y_train)

# Prédiction des labels
y_pred = knn.predict(X_test)

# Évaluation du modèle
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
matrix = confusion_matrix(y_test, y_pred)

print("Accuracy : {:.2f}%".format(accuracy * 100))
print("Classification Report :\n", report)

plt.figure(figsize=(10, 7))
sns.heatmap(cm, annot=True, fmt="d", cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Animal Sound Classification')
plt.show()
matrix = confusion_matrix(y_test, y_pred)
print("Confusion Matrix :\n", matrix)

from sklearn.preprocessing import StandardScaler
### Normalise version of KNN
def extract_features(file_path):
    y, sr = librosa.load(file_path, sr=None)

    # MFCC
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

    # Extraction des features
    features = np.concatenate((mfcc.mean(axis=1), mfcc.std(axis=1)))

    return features

# Initialize arrays
file_paths = []
labels = []
features = []

# Dataset path
folder_path = "animal_sounds"

# Iterate over files and extract features
for root, dirs, files in os.walk(folder_path):
    for file in files:
        if file.endswith(".wav") or file.endswith(".mp3"):
            file_path = os.path.join(root, file)
            label = os.path.basename(root)
            file_paths.append(file_path)
            labels.append(label)
            features.append(extract_features(file_path))

# Convert to numpy arrays
X = np.array(features)
y = np.array(labels)

# Division des données en train et test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalisation des données
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Création du KNN
knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3, weights='distance')

# Entraînement du KNN
knn.fit(X_train, y_train)

# Prédiction des labels
y_pred = knn.predict(X_test)

# Évaluation du modèle
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
matrix = confusion_matrix(y_test, y_pred)

print("Accuracy : {:.2f}%".format(accuracy * 100))
print("Classification Report :\n", report)
print("Confusion Matrix :\n", matrix)

import os
import numpy as np
import librosa
from sklearn.metrics import  classification_report, confusion_matrix
import matplotlib.pyplot as plt

def extract_features(file_path):
    y, sr = librosa.load(file_path, sr=None)

    # MFCC
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

    # Extraction des features
    features = np.concatenate((mfcc.mean(axis=1), mfcc.std(axis=1)))

    return features

# Initialize arrays
file_paths = []
labels = []
features = []

# Dataset path
folder_path = "../ani_sound"

# Iterate over files and extract features
for root, dirs, files in os.walk(folder_path):
    for file in files:
        if file.endswith(".wav") or file.endswith(".mp3"):
            file_path = os.path.join(root, file)
            label = os.path.basename(root)  # Nom du dossier comme étiquette
            file_paths.append(file_path)
            labels.append(label)
            features.append(extract_features(file_path))

# Convert to numpy arrays
X = np.array(features)
y = np.array(labels)

# Liste des classes disponibles
classes = np.unique(y)

# Initialiser les listes pour stocker les résultats
num_classes = []
accuracies = []

# Boucle pour mesurer les performances selon le nombre de classes
for k in range(2, len(classes) + 1):
    selected_classes = classes[:k]

    # Filtrer les données pour les classes sélectionnées
    mask = np.isin(y, selected_classes)
    X_filtered = X[mask]
    y_filtered = y[mask]

    # Division des données en train et test
    X_train, X_test, y_train, y_test = train_test_split(X_filtered, y_filtered, test_size=0.2, random_state=42)

    # Normalisation des données
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Création du KNN
    knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=3, weights='distance')

    # Entraînement du KNN
    knn.fit(X_train, y_train)

    # Prédiction des labels
    y_pred = knn.predict(X_test)

    # Évaluation du modèle
    accuracy = accuracy_score(y_test, y_pred)
    num_classes.append(k)
    accuracies.append(accuracy)

    print(f"Nombre de classes : {k}, Accuracy : {accuracy:.2f}")

plt.figure(figsize=(10, 6))
plt.plot(num_classes, accuracies, marker='o')
plt.xlabel("Nombre de Classes")
plt.ylabel("Accuracy")
plt.title("Accuracy en Fonction du Nombre de Classes")
plt.grid()
plt.show()